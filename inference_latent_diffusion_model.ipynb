{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff1a600",
   "metadata": {},
   "source": [
    "# This notebook is an example notebook to inference the latent diffusion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae80fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from omegaconf import OmegaConf\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/ldm\")\n",
    "from ldm.models.diffusion.ddim import DDIMSampler\n",
    "from ldm.util import instantiate_from_config\n",
    "\n",
    "transform_PIL = T.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce79696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "yaml_path = \"ldm/models/ldm/inpainting_big/config.yaml\"\n",
    "# model_path = \"ldm/models/ldm/inpainting_big/last.ckpt\"\n",
    "model_path = \"logs/checkpoints/last-v2.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949f2472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "\n",
    "def create_model(device):\n",
    "\n",
    "    # load config and checkpoint\n",
    "    config = OmegaConf.load(yaml_path)\n",
    "    config.model[\"params\"][\"ckpt_path\"] = model_path\n",
    "\n",
    "    model = instantiate_from_config(config.model)\n",
    "    sampler = DDIMSampler(model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    return model, sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masked_image(image, mask):\n",
    "    # Create a copy of the original image\n",
    "    masked_image = image.copy()\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    masked_image.paste(Image.new(\"RGB\", image.size, (0, 0, 0)), mask=mask)\n",
    "\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def random_rectangle_mask(image):\n",
    "    # Create a copy of the original image\n",
    "    masked_image = image.copy()\n",
    "    image_x, image_y = image.size\n",
    "\n",
    "    width = random.randint(70, 150)\n",
    "    height = int(width * random.uniform(0.7, 1.5))\n",
    "\n",
    "    # Create a black background mask\n",
    "    mask = Image.new(\"L\", (image_x, image_y), 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "\n",
    "    # Randomly generate the coordinates for the top-left and bottom-right corners of the rectangle\n",
    "    x1 = random.randint(0, image.size[0] - width)\n",
    "    y1 = random.randint(0, image.size[1] - height)\n",
    "    x2 = x1 + width\n",
    "    y2 = y1 + height\n",
    "\n",
    "    # Draw a white rectangle on the mask\n",
    "    draw.rectangle([x1, y1, x2, y2], fill=255)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    create_masked_image(image, mask)\n",
    "\n",
    "    return image, mask, masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce72c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(image, mask):\n",
    "\n",
    "    # creating a 3 dimensional mask\n",
    "    mask = np.array(mask)\n",
    "    mask = np.expand_dims(mask, axis=2)\n",
    "\n",
    "    # normalzie and transform the image into tensor\n",
    "    image = np.array(image.convert(\"RGB\"))\n",
    "    image = image.astype(np.float32) / 255.0  #\n",
    "    image = image[None].transpose(0, 3, 1, 2)\n",
    "    image = torch.from_numpy(image)\n",
    "\n",
    "    # normalzie and transform the mask into tensor\n",
    "    mask = mask.astype(np.float32) / 255.0  #\n",
    "    mask[mask < 0.1] = 0\n",
    "    mask[mask >= 0.1] = 1\n",
    "    mask = mask[None].transpose(0, 3, 1, 2)\n",
    "\n",
    "    # produce the masked image by subtraction\n",
    "    mask = torch.from_numpy(mask)\n",
    "    masked_image = (1 - mask) * image\n",
    "\n",
    "    batch = {\n",
    "        \"image_tensor\": image,\n",
    "        \"mask_tensor\": mask,\n",
    "        \"masked_image_tensor\": masked_image,\n",
    "    }\n",
    "    for k in batch:\n",
    "        batch[k] = batch[k] * 2.0 - 1.0\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2402a01d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, sampler = create_model(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b5e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"./splits/test/images/20230707_005855_CAM_MAC1_5_BT.jpg\").resize(\n",
    "    (512, 512)\n",
    ")\n",
    "\n",
    "mask = (\n",
    "    Image.open(\n",
    "        \"./splits/test/masks/20231106_175846_CAM_MAC1_5_BT.jpg\",\n",
    "    )\n",
    "    .resize((512, 512))\n",
    "    .convert(\"L\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b927c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image, mask, masked_image = random_rectangle_mask(image)\n",
    "masked_image = create_masked_image(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60c763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    1, 3, figsize=(12, 4)\n",
    ")  # Create a 1x3 grid for displaying 3 images\n",
    "\n",
    "# Display each image on a separate subplot\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title(\"image\")\n",
    "\n",
    "axes[1].imshow(mask)\n",
    "axes[1].set_title(\"mask\")\n",
    "\n",
    "axes[2].imshow(masked_image)\n",
    "axes[2].set_title(\"masked_image\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e712a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "# convert PIL image into input Torch Tensor\n",
    "batch = process_data(image, mask)\n",
    "image_tensor = batch[\"image_tensor\"]\n",
    "mask_tensor = batch[\"mask_tensor\"]\n",
    "masked_image_tensor = batch[\"masked_image_tensor\"]\n",
    "\n",
    "\n",
    "# encode masked image and concat downsampled mask\n",
    "c = model.cond_stage_model.encode(masked_image_tensor.to(device))\n",
    "\n",
    "# the mask is frst being downsampled\n",
    "cc = torch.nn.functional.interpolate(mask_tensor.to(device), size=c.shape[-2:])\n",
    "# concat the masked image and downsampled mask\n",
    "c = torch.cat((c, cc), dim=1)\n",
    "shape = (c.shape[1] - 1,) + c.shape[2:]\n",
    "\n",
    "# diffusion process\n",
    "samples_ddim, _ = sampler.sample(\n",
    "    S=50, conditioning=c, batch_size=c.shape[0], shape=shape, verbose=False\n",
    ")\n",
    "\n",
    "# decode the latent vector (output)\n",
    "x_samples_ddim = model.decode_first_stage(samples_ddim)\n",
    "\n",
    "\n",
    "# denormalize the output\n",
    "predicted_image_clamped = torch.clamp((x_samples_ddim + 1.0) / 2.0, min=0.0, max=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccb4b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_PIL = transform_PIL(predicted_image_clamped[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d915c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    1, 3, figsize=(12, 4)\n",
    ")  # Create a 1x3 grid for displaying 3 images\n",
    "\n",
    "# Display each image on a separate subplot\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title(\"original image\")\n",
    "\n",
    "axes[1].imshow(mask)\n",
    "axes[1].set_title(\"masked image\")\n",
    "\n",
    "axes[2].imshow(output_PIL)\n",
    "axes[2].set_title(\"Inpainted Image\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
